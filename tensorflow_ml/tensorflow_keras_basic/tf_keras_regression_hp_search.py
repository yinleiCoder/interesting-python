# -*- coding: utf-8 -*-
"""tf_keras_regression_hp_search.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W-LlohpjL2NLG1-WtKcWJgw_G2gw5En9

# **超参数搜索**

- 神经网络中有很多训练过程中不变的参数
  - 网络结构参数：几层、每层宽度、每层激活函数等
  - 训练参数: batch_size、学习率、学习率衰减算法等
- 手工去尝试需要耗费人力
- 搜索策略
  - 网格搜索
  - 随机搜索
  - 遗传算法搜索
  - 启发式搜索(使用循环神经网络生成参数，使用强化学习来进行反馈，使用模型来训练生成参数)
"""

import matplotlib as mpl 
import matplotlib.pyplot as plt 
import numpy as np 
import sklearn
import pandas as pd 
import os 
import sys 
import time 
import tensorflow as tf
from tensorflow import keras

print(tf.__version__)
print(sys.version_info)
for module in mpl, np, pd, sklearn, tf, keras:
  print(module.__name__, module.__version__)

# 数据集展示与读取(关于加利福尼亚房价的数据集，每个样本的特征维度是8，收入、房龄、房间数量、卧室数量、街道人口、入住人家、房屋经度、房屋维度等)
from sklearn.datasets import fetch_california_housing
housing = fetch_california_housing()
print(housing.DESCR)
print(housing.data.shape)
print(housing.target.shape)

# 划分数据集
from sklearn.model_selection import train_test_split
# test_size指划分的训练集和测试集的比例。默认为0.25表示数据分为4份，测试集占1份
x_train_all, x_test, y_train_all, y_test = train_test_split(housing.data, housing.target, random_state=7)
x_train, x_valid, y_train, y_valid = train_test_split(x_train_all, y_train_all, random_state=11)
print(x_train.shape, y_train.shape)
print(x_valid.shape, y_valid.shape)
print(x_test.shape, y_test.shape)

# 归一化
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_valid_scaled = scaler.transform(x_valid)
x_test_scaled = scaler.transform(x_test)

# 手动实现超参数搜索
# learning_rate: [1e-4, 3e-4, 1e-3, 3e-3, 1e-2, 3e-2]
# W = W + grad *learning_rate
"""
learning_rate = [1e-4, 3e-4, 1e-3, 3e-3, 1e-2, 3e-2]
histories = []
for lr in learning_rate:
  model = keras.models.Sequential([
      keras.layers.Dense(30, activation='relu', input_shape=x_train.shape[1:]),
      keras.layers.Dense(1),
  ])
  optimizer = keras.optimizers.SGD(lr)
  model.compile(loss='mean_squared_error', optimizer=optimizer)
  callbacks = [
      keras.callbacks.EarlyStopping(patience=5, min_delta=1e-2),
  ]
  history = model.fit(x_train_scaled, y_train, epochs=100, 
              validation_data=(x_valid_scaled, y_valid),
              callbacks=callbacks)
  histories.append(history)
"""

# sklearn实现超参数搜索RandomizedSearchCV
# 1.转化为sklearn的model
# 2.定义参数集合
# 3.搜索参数
def build_model(hidden_layers=1, layer_size=30, learning_rate=3e-3):
  model = keras.models.Sequential()
  model.add(keras.layers.Dense(layer_size, activation='relu', input_shape=x_train.shape[1:]))
  for _ in range(hidden_layers - 1):
    model.add(keras.layers.Dense(layer_size, activation='relu'))
  model.add(keras.layers.Dense(1))
  optimizer = keras.optimizers.SGD(learning_rate)
  model.compile(loss='mse', optimizer=optimizer)
  return model

sklearn_model = keras.wrappers.scikit_learn.KerasRegressor(build_model)
callbacks = [
    keras.callbacks.EarlyStopping(patience=5, min_delta=1e-2),
]
history = sklearn_model.fit(x_train_scaled, y_train, epochs=100, 
            validation_data=(x_valid_scaled, y_valid),
            callbacks=callbacks)

def plot_learning_curves(history):
  pd.DataFrame(history.history).plot(figsize=(8, 5))
  plt.grid(True)
  plt.gca().set_ylim(0, 1)
  plt.show()

plot_learning_curves(history)
# for lr, history in zip(learning_rate, histories):
#   print(f'learning rate: {lr}')
#   plot_learning_curves(history)

from scipy.stats import reciprocal
# f(x) = 1/(x*log(b/a)) a<=x<=b

# 2.定义参数集合
param_distribution = {
    "hidden_layers": [1, 2, 3, 4],
    "layer_size": np.arange(1, 100),
    "learning_rate": reciprocal(1e-4, 1e-2)
}
from sklearn.model_selection import RandomizedSearchCV
random_search_cv = RandomizedSearchCV(sklearn_model, 
                    param_distribution,
                    n_iter=10,
                    n_jobs=1)
random_search_cv.fit(x_train_scaled, y_train, epochs=100,
          validation_data=(x_valid_scaled, y_valid),
          callbacks=callbacks)

from scipy.stats import reciprocal
reciprocal.rvs(1e-4, 1e-2, size=10)

random_search_cv.best_params_
random_search_cv.best_score_
random_search_cv.best_estimator_

model = random_search_cv.best_estimator_.model
model.evaluate(x_test_scaled, y_test)

